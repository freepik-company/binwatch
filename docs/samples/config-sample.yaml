---
# BinWatch configuration file
# This file is written in YAML format

# ATTENTION!
# Also you can use environment variables in the configuration file. The environment variables must be written in the
# format $ENV_VAR_NAME. The environment variables will be replaced by its value in execution time.

# Logger configuration
logger:
  # debug, info, warn, error, dpanic, panic, fatal
  level: info
  # console or json
  encoding: json

# Server id of the binwatch instance. Can be set via environment variable which will be replaced at runtime
# It must have the format <hostname>:<port> or <ip>:<port> to be used in the hashring
server_id: "$HOSTNAME:$PORT"

# Number of workers to process the events
max_workers: 10

# Flow control configuration to control the memory usage by the event connectors queue
flow_control:
  # Check interval to check the queue size
  check_interval: 100ms
  # List of thresholds to control the sleep time of the workers to avoid memory overflow
  thresholds:
    - queue_size: 1
      sleep_time: 10ms
    - queue_size: 10
      sleep_time: 100ms
    - queue_size: 100
      sleep_time: 1s
      
# Hashring configuration for HA and load balancing purposes
# hashring:

  # Sync worker time in milliseconds to sync the ring nodes when a new node is added or removed from the ring
  # sync_worker_time_ms: 300

  # API port to expose the hashring
  # api_port: $PORT

  # For static ring discovery we need to define the server names that are part of the ring
  # static_ring_discovery:
  #  hosts:
  #    - test:8080
  #    - test2:8081

  # For DNS ring discovery we need to define the domain and the port of the headless service to get
  # the list of server names that are part of the ring
  # Recommended for kubernetes deployments with headless services
  # dns_ring_discovery:
  #   domain: "dns.example.com"
  #   port: 8080

# Sources configuration
# List of sources to watch for changes in the database binlog
sources:

  # MySQL source configuration
  mysql:
    host: "$MYSQL_HOST"
    port: $MYSQL_PORT
    user: "$MYSQL_USER"
    password: "$MYSQL_PASSWORD"

    # Server ID must be unique across all MySQL servers
    server_id: 100

    # Read timeout
    read_timeout: 90s

    # Heartbeat period
    heartbeat_period: 60s

    # Flavor of the database. MySQL or MariaDB
    flavor: mysql

    # Just listen for events in this database-table pairs
    filter_tables:
      - database: test
        table: test

    # Mysqldump configuration for sync command. Just can dump an entire database, many databases or many tables for ONE database.
    # If many databases are specefied with tables, the tables will be ignored.
    # Empty dump_config disables the previous mysql dump feature.
    dump_config:
      databases:
        - test
      tables:
        - test
      # Extra options for mysqldump command
      # mysqldump_extra_options:
      #   - "--single-transaction"
      # Default value is /usr/bin/mysqldump, path where mysqldump is located in the Docker image
      # mysqldump_bin_path: "/opt/homebrew/bin/mysqldump"

# Data connectors configuration
# List of connectors to send the data to
connectors:

  # Routes configuration for the connectors. It determines the events that will be sent to each connectors and
  # the data format that will be sent to the connector.
  # Events can be insert, update or delete
  # Data format is in golang template format. The data read from the binlog will be passed to the template as .data
  routes:
    - events: ["insert", "update", "delete"]
      connector: webhook-test
      data: |
        {{- printf `{ "index": "test", "id": %v }` .data.id }}

  # Connectors configuration. Just pubsub and webhook supported at the moment.

  # Webhook connector configuration
  webhook:
    - name: webhook-test
      tls_skip_verify: false
      url: "https://webhook.site/<id>"
      method: "POST"
      headers:
        X-BinWatch: "true"
    # credentials:
    #  username: "$WEBHOOK_USERNAME"
    #  password: "$WEBHOOK_PASSWORD"